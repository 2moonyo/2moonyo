{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2moonyo/2moonyo/blob/main/Tumi_Modiba_pyspark_exercise_V5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PySpark homework assignment\n",
        "\n",
        "## Context\n",
        "\n",
        "The goal of this assignment is to get view on your coding workflow & style.  Your main focus should be creating performant & robust code for data manipulations.  \n",
        "\n",
        "For a homework assignment, we cannot grant you access to our infrastructure (Cloudera data platform on prem: a spark cluster deployment on Yarn).  Since the focus is on development, we provided a template notebook to get up and running very quickly on Google Colab.  \n",
        "\n",
        "You have the freedom to perform this assignment on any spark3+ infrastructure.  If want to use a local or cloud setup, go for it!\n",
        "\n",
        "Some of the tasks are open for interpretation.  This allows us to assess business understanding and relevant field experience.  These tasks are not pass or fail checks.  During the interview we'll ask details about the choice(s) you made.\n",
        "\n",
        "For the assignment, you'll be working with store location data.  You might be familiar with the phrase \"Location, location, location\" from the real-estate context.  The same house can have a different selling price based on the location.  In fast moving consumer goods (FMCG), location is one of the most crucial aspects:\n",
        "\n",
        "* Proximity & accessibility to customers increases convenience\n",
        "* Proximity to competitors increases market pressure\n",
        "* It has impact on the supply chain\n",
        "\n",
        "## Evaluation criteria\n",
        "\n",
        "1. Software engineering\n",
        "   1. Clean code (e.g. using meaningful names)\n",
        "   1. Robust & efficient code\n",
        "   1. Styling (e.g. PEP8, or Google style guide)\n",
        "   1. Documentation(e.g. docstrings)\n",
        "   1. Design (e.g. SOLID principles)\n",
        "1. Workflow\n",
        "   1. How you use Git\n",
        "   1. How you structure your assignment\n",
        "   1. Owning mistakes\n",
        "   1. Rationale for design decisions\n",
        "   1. Making your solution accessible to others\n",
        "1. Business context\n",
        "   1. GDPR\n",
        "   1. Fast moving consumer goods\n",
        "1.(optional: own infra) System engineering\n",
        "   1. What setup did you use?\n",
        "   1. How did you set it up?\n",
        "\n",
        "## Deliverables we expect\n",
        "\n",
        "1. Private GitHub repo\n",
        "   1. Colab allows you to save to GitHub\n",
        "   1. Invite my username to your private repo as contributor\n",
        "1. README.md with relevant content\n",
        "1. Code relevant to the assignment\n"
      ],
      "metadata": {
        "id": "MMCkWQR0NQh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google colab spark setup"
      ],
      "metadata": {
        "id": "ZWyMNpBNON-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3RiQgV1aNOJD"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import environ\n",
        "import findspark"
      ],
      "metadata": {
        "id": "V6xZShWarSWL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting environment variables\n",
        "environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\""
      ],
      "metadata": {
        "id": "Cvm3vu7cNSzV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init spark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "8y6JdEBrO43D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# spark.sql.repl.eagerEval.enabled: Property used to format output tables better\n",
        "\n",
        "spark = (\n",
        "    SparkSession\n",
        "    .builder\n",
        "    .appName(\"cg-pyspark-assignment\")\n",
        "    .master(\"local\")\n",
        "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
        "    .getOrCreate()\n",
        "  )\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "o5-SFL47PQfJ",
        "outputId": "6204a378-c892-4a6a-eee2-7b1bead8b25d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ea014674f10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ad4e5bdd3231:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>cg-pyspark-assignment</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the assignment data\n",
        "\n",
        "This will call the api and save the results in current working directory as .json files"
      ],
      "metadata": {
        "id": "QWtk5p_punuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/clp-places > clp-places.json\n",
        "!curl https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/okay-places > okay-places.json\n",
        "!curl https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/spar-places > spar-places.json\n",
        "!curl https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/dats-places > dats-places.json\n",
        "!curl https://ecgplacesmw.colruytgroup.com/ecgplacesmw/v3/nl/places/filter/cogo-colpnts > cogo-colpnts.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-UEk918o3Xt",
        "outputId": "8ef3a864-75c7-426a-a4e8-1151decb8a2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  224k    0  224k    0     0   154k      0 --:--:--  0:00:01 --:--:--  154k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  144k    0  144k    0     0   149k      0 --:--:-- --:--:-- --:--:--  149k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  167k    0  167k    0     0   132k      0 --:--:--  0:00:01 --:--:--  132k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 88519    0 88519    0     0   116k      0 --:--:-- --:--:-- --:--:--  116k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  256k    0  256k    0     0   236k      0 --:--:--  0:00:01 --:--:--  236k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment instructions\n",
        "\n",
        "1. Download the data from api\n",
        "1. Create a logger object that logs to a file \"assignment.log\"\n",
        "   1. You can add whatever logging config you want or need\n",
        "   1. At least on Filehandler based on instructions\n",
        "1. implement get_data_by_brand function\n",
        "   1. Follow instructions in docstring\n",
        "   1. df_clp code line should work\n",
        "1. No more handholding ... :-)\n",
        "1. Create a single object (dataframe) that:\n",
        "   1. Contains data from **all brands**\n",
        "      1. Not every brand has the same columns!\n",
        "   1. Drop placeSearchOpeningHours\n",
        "   1. You can keep sellingPartners as an array\n",
        "   1. Extract \"postal_code\" from address\n",
        "   1. Create new column \"province\" derived from postal_code\n",
        "   1. Transform geoCoordinates into lat and lon column\n",
        "   1. One-hot-encode the handoverServices\n",
        "   1. Pretend houseNumber and streetName are GDPR sensitive.\n",
        "      1. How would you anonymize this data for unauthorized users?\n",
        "      1. (optional) Implement the above\n",
        "      1. How would you show the real data to authorized users?\n",
        "      1. (optional) Implement the above\n",
        "1. Save the end result as a parquet file\n",
        "   1. (optional)partitioning?\n",
        "\n",
        "**postal_code** logic:\n",
        "* \"Brussel\": 1000-1299  \n",
        "* \"Waals-Brabant\": 1300-1499  \n",
        "* \"Vlaams-Brabant\": 1500-1999, 3000-3499  \n",
        "* \"Antwerpen\": 2000-2999  \n",
        "* \"Limburg\": 3500-3999  \n",
        "* \"Luik\": 4000-4999  \n",
        "* \"Namen\": 5000-5999  \n",
        "* \"Henegouwen\": 6000-6599,7000-7999  \n",
        "* \"Luxemburg\": 6600-6999  \n",
        "* \"West-Vlaanderen\": 8000-8999  \n",
        "* \"Oost-Vlaanderen\": 9000-9999"
      ],
      "metadata": {
        "id": "VyvIVnyivCpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Initialize bash for directory formatting\n",
        "\n",
        "\n",
        "# Create a data folder\n",
        "mkdir -p /content/data\n",
        "\n",
        "# Move all JSON files to data folder\n",
        "mv /content/*.json /content/data/\n",
        "\n",
        "# Force remove sample_data\n",
        "rm -rf /content/sample_data/"
      ],
      "metadata": {
        "id": "SZ3Muo3j2ib7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Package installer for accessing .env\n",
        "!pip install -q python-dotenv"
      ],
      "metadata": {
        "id": "6EoPHrmOESHu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a .env file with the SECRET_KEY value\n",
        "# This is where you create the .env which you will share privately\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(\"SECRET_KEY=fairplay2025\\n\")"
      ],
      "metadata": {
        "id": "RBLx0w1MK91S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()  # Load environment variables from .env\n",
        "\n",
        "import os\n",
        "SECRET_KEY = os.getenv(\"SECRET_KEY\")\n",
        "\n",
        "# Optional: confirm it loaded (remove after testing)\n",
        "print(\"Loaded SECRET_KEY:\", SECRET_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBBUXNYwLBWD",
        "outputId": "dd28ab4f-8d2e-46f0-9832-8ef611cda1ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SECRET_KEY: fairplay2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import statements should go here\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import Optional\n",
        "from getpass import getpass\n",
        "from datetime import datetime\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql import SparkSession\n",
        "from logging import getLogger, Logger\n",
        "from pyspark.sql.types import StructType, ArrayType, StructField, StringType, IntegerType, DoubleType\n",
        "from pyspark.sql.functions import col, lit, broadcast, explode, create_map, to_json, from_json, array_contains, when\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DlsAnfxdxsT3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks for file installation\n",
        "!cat .env\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeYCCwWBEJHx",
        "outputId": "fc1f6454-d8ec-4a38-867a-c78ff065a8dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SECRET_KEY=fairplay2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOwuGewDGz3B",
        "outputId": "47e4151e-d681-4362-8036-9a66446509b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGGING SETUP (conforms to NDJSON standard)\n",
        "\n",
        "LOG_FILE = \"assignment.log\"\n",
        "LOGGER = logging.getLogger(\"data_loader\")\n",
        "# Attach file handler if not already present\n",
        "if not LOGGER.handlers:\n",
        "    file_handler = logging.FileHandler(LOG_FILE, mode='a')\n",
        "    formatter = logging.Formatter('%(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "    LOGGER.setLevel(logging.INFO)\n",
        "    LOGGER.addHandler(file_handler)\n",
        "    LOGGER.propagate = False"
      ],
      "metadata": {
        "id": "a1qmDV8uFmFG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBAL CONSTANTS & DATA STRUCTURES\n",
        "\n",
        "# Directory with data folder for json path\n",
        "BRAND_PATHS = {\n",
        "    \"clp\": \"/content/data/clp-places.json\",\n",
        "    \"okay\": \"/content/data/okay-places.json\",\n",
        "    \"spar\": \"/content/data/spar-places.json\",\n",
        "    \"dats\": \"/content/data/dats-places.json\",\n",
        "    \"cogo\": \"/content/data/cogo-colpnts.json\"\n",
        "}\n",
        "\n",
        "# Global dictionary for individual dataframes\n",
        "  #  - Holds final Brand dataframe\n",
        "BRAND_DATAFRAMES = {}\n",
        "\n",
        "# Postcode ranges list mapping to provinces\n",
        "province_ranges = [\n",
        "    (\"Brussel\", 1000, 1299),\n",
        "    (\"Waals-Brabant\", 1300, 1499),\n",
        "    (\"Vlaams-Brabant\", 1500, 1999),\n",
        "    (\"Vlaams-Brabant\", 3000, 3499),\n",
        "    (\"Antwerpen\", 2000, 2999),\n",
        "    (\"Limburg\", 3500, 3999),\n",
        "    (\"Luik\", 4000, 4999),\n",
        "    (\"Namen\", 5000, 5999),\n",
        "    (\"Henegouwen\", 6000, 6599),\n",
        "    (\"Henegouwen\", 7000, 7999),\n",
        "    (\"Luxemburg\", 6600, 6999),\n",
        "    (\"West-Vlaanderen\", 8000, 8999),\n",
        "    (\"Oost-Vlaanderen\", 9000, 9999),\n",
        "]\n",
        "\n",
        "# Define Schema and datatype for province_df join\n",
        "schema = StructType([\n",
        "    StructField(\"province\", StringType(), True),\n",
        "    StructField(\"start_pc\", IntegerType(), True),\n",
        "    StructField(\"end_pc\", IntegerType(), True),\n",
        "])\n",
        "\n",
        "# Create province_df dataframe with schema\n",
        "province_df = spark.createDataFrame(province_ranges, schema)"
      ],
      "metadata": {
        "id": "IR3IwpBSGGDX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_dataframe_summary(df, label: str = \"DataFrame\", logger: Optional[Logger] = LOGGER):\n",
        "    \"\"\"\n",
        "    Logs details of a DataFrame: row/column count, column names, data types, and missing values.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Count rows & columns\n",
        "        row_count = df.count()\n",
        "        col_count = len(df.columns)\n",
        "        col_names = df.columns\n",
        "        dtypes = df.dtypes  # List of (columnName, dataType)\n",
        "\n",
        "        # Count non-null entries per column\n",
        "        non_null_counts = (\n",
        "            df.select([col(c).isNotNull().cast(\"int\").alias(c) for c in df.columns])\n",
        "              .groupBy().sum()\n",
        "              .collect()[0]\n",
        "              .asDict()\n",
        "        )\n",
        "\n",
        "        # Log aggregations\n",
        "        logger.info(json.dumps({\n",
        "            \"event\": \"dataframe_summary\",\n",
        "            \"label\": label,\n",
        "            \"row_count\": row_count,\n",
        "            \"column_count\": col_count,\n",
        "            \"column_names\": col_names,\n",
        "            \"data_types\": dtypes,\n",
        "            \"non_null_counts\": non_null_counts,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(json.dumps({\n",
        "            \"event\": \"summary_failure\",\n",
        "            \"label\": label,\n",
        "            \"error\": str(e),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))"
      ],
      "metadata": {
        "id": "0TAafbsiKTSo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def check_access_and_mask(df: DataFrame, logger: Logger = LOGGER) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Prompts for a key. If incorrect, masks sensitive fields (house number and street name).\n",
        "    \"\"\"\n",
        "\n",
        "    user_key = getpass(\"🔐 Enter access key to view full address: \")\n",
        "\n",
        "    # Passkey conditional\n",
        "    if user_key != SECRET_KEY:\n",
        "        masked_df = (\n",
        "            df.withColumn(\"address_streetName\", lit(\"xxx\"))\n",
        "              .withColumn(\"address_houseNumber\", lit(\"xxx\"))\n",
        "        )\n",
        "\n",
        "        logger.info(json.dumps({\n",
        "            \"event\": \"address_masked\",\n",
        "            \"status\": \"unauthorized\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        return masked_df\n",
        "\n",
        "    else:\n",
        "        logger.info(json.dumps({\n",
        "            \"event\": \"address_revealed\",\n",
        "            \"status\": \"authorized\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        return df"
      ],
      "metadata": {
        "id": "Wz2gFI9UyNnf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_by_brand(brand: str, logger: Optional[Logger] = LOGGER) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Loads a JSON file for a specific brand, logs schema, flattens it, and applies masking.\n",
        "    \"\"\"\n",
        "    global BRAND_DATAFRAMES\n",
        "    brand = brand.lower()\n",
        "\n",
        "    if brand not in BRAND_PATHS:\n",
        "        logger.error(json.dumps({\n",
        "            \"event\": \"unsupported_brand\",\n",
        "            \"brand\": brand,\n",
        "            \"message\": \"Unsupported brand provided\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        raise ValueError(f\"Unsupported brand: {brand}\")\n",
        "\n",
        "    path = BRAND_PATHS[brand]\n",
        "    if not os.path.exists(path):\n",
        "        logger.error(json.dumps({\n",
        "            \"event\": \"file_not_found\",\n",
        "            \"brand\": brand,\n",
        "            \"path\": path,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        raise FileNotFoundError(f\"No data found at: {path}\")\n",
        "\n",
        "    try:\n",
        "        # Load JSON as-is\n",
        "        df = spark.read.option(\"multiline\", \"true\").json(path)\n",
        "\n",
        "        # Print raw nested schema\n",
        "        print(f\"\\n🔍 Raw schema for brand '{brand}':\")\n",
        "        df.printSchema()\n",
        "\n",
        "        # Log row/column counts\n",
        "        row_count = df.count()\n",
        "        if row_count == 0:\n",
        "            logger.warning(json.dumps({\n",
        "                \"event\": \"empty_data_warning\",\n",
        "                \"brand\": brand,\n",
        "                \"path\": path,\n",
        "                \"message\": \"No records found.\",\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }))\n",
        "        else:\n",
        "            logger.info(json.dumps({\n",
        "                \"event\": \"load_success\",\n",
        "                \"brand\": brand,\n",
        "                \"path\": path,\n",
        "                \"row_count\": row_count,\n",
        "                \"column_count\": len(df.columns),\n",
        "                \"columns\": df.columns,\n",
        "                \"schema\": df.schema.simpleString(),\n",
        "                \"timestamp\": datetime.now().isoformat()\n",
        "            }))\n",
        "\n",
        "        # Flatten after printing original schema\n",
        "        df_flat = flatten_df(df, logger=logger)\n",
        "\n",
        "\n",
        "        # Expose global variable like df_clp, df_spar, etc.\n",
        "        globals()[f\"df_{brand}\"] = df_flat\n",
        "        BRAND_DATAFRAMES[brand] = df_flat\n",
        "\n",
        "        return df_flat\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.exception(json.dumps({\n",
        "            \"event\": \"load_or_flatten_failure\",\n",
        "            \"brand\": brand,\n",
        "            \"error\": str(e),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "CdUCdta0JFC5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_flattened_fields(schema, prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Recursively flattens a JSON schema for nested dictionaries.\n",
        "    \"\"\"\n",
        "    fields = []\n",
        "\n",
        "    for field in schema.fields:\n",
        "        name = field.name\n",
        "        dtype = field.dataType\n",
        "        full_name = f\"{prefix}.{name}\" if prefix else name\n",
        "        alias_name = full_name.replace(\".\", \"_\")\n",
        "\n",
        "        if isinstance(dtype, StructType):\n",
        "            fields += get_flattened_fields(dtype, full_name)\n",
        "        elif isinstance(dtype, ArrayType):\n",
        "            fields.append(to_json(col(full_name)).alias(alias_name))\n",
        "        else:\n",
        "            fields.append(col(full_name).alias(alias_name))\n",
        "\n",
        "    return fields"
      ],
      "metadata": {
        "id": "sRv98BG6IuBW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_df(df, logger: Optional[Logger] = LOGGER) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Applies flattening to a DataFrame with nested structures. Logs before and after.\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(json.dumps({\n",
        "        \"event\": \"flatten_start\",\n",
        "        \"message\": \"Flattening DataFrame schema\",\n",
        "        \"original_columns\": df.columns,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }))\n",
        "\n",
        "    try:\n",
        "        flattened = df.select(*get_flattened_fields(df.schema))\n",
        "        logger.info(json.dumps({\n",
        "            \"event\": \"flatten_success\",\n",
        "            \"message\": \"Flattened DataFrame\",\n",
        "            \"flattened_columns\": flattened.columns,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        return flattened\n",
        "    except Exception as e:\n",
        "        logger.exception(json.dumps({\n",
        "            \"event\": \"flatten_error\",\n",
        "            \"message\": \"Failed to flatten DataFrame\",\n",
        "            \"error\": str(e),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "P1WiufzMIzQb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_to_reference(df, brand_name, ref_cols, all_cols):\n",
        "    \"\"\"\n",
        "    Aligns a DataFrame to the reference schema for union operations. Adds missing columns with nulls.\n",
        "    \"\"\"\n",
        "\n",
        "    for col_name in all_cols:\n",
        "        if col_name not in df.columns:\n",
        "            df = df.withColumn(col_name, lit(None))\n",
        "\n",
        "    # Add or overwrite Brand column\n",
        "    df = df.withColumn(\"Brand\", lit(brand_name))\n",
        "\n",
        "    # Set to check for duplicates\n",
        "    seen = set()\n",
        "    final_columns = [\"Brand\"]  # Always start with Brand\n",
        "    for col_name in list(ref_cols) + list(all_cols):\n",
        "        if col_name != \"Brand\" and col_name not in seen:\n",
        "            final_columns.append(col_name)\n",
        "            seen.add(col_name)\n",
        "\n",
        "    return df.select(*final_columns)\n"
      ],
      "metadata": {
        "id": "_L744FQKLg2C"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def union_all_brands(dataframes: dict, logger: Logger = LOGGER) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Combines all brand DataFrames into a single one.\n",
        "    \"\"\"\n",
        "    widest_df_entry = max(dataframes.items(), key=lambda item: len(item[1].columns))\n",
        "    reference_columns = widest_df_entry[1].columns\n",
        "    all_columns = set().union(*[set(df.columns) for df in dataframes.values()])\n",
        "\n",
        "    aligned = [\n",
        "        align_to_reference(df.withColumn(\"Brand\", lit(brand)), brand, reference_columns, all_columns)\n",
        "        for brand, df in dataframes.items()\n",
        "    ]\n",
        "\n",
        "    df_all = aligned[0]\n",
        "    for df in aligned[1:]:\n",
        "        df_all = df_all.unionByName(df, allowMissingColumns=True)\n",
        "\n",
        "    if \"placeSearchOpeningHours\" in df_all.columns:\n",
        "        df_all = df_all.drop(\"placeSearchOpeningHours\")\n",
        "\n",
        "    logger.info(json.dumps({\n",
        "        \"event\": \"union_complete\",\n",
        "        \"row_count\": df_all.count(),\n",
        "        \"column_count\": len(df_all.columns),\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }))\n",
        "\n",
        "    return df_all"
      ],
      "metadata": {
        "id": "UyjwVTF6EhJU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enrich_with_province(df: DataFrame, province_df: DataFrame, logger: Logger = LOGGER) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Joins a DataFrame with province information using postcode ranges.\n",
        "    \"\"\"\n",
        "\n",
        "    df_with_province = df.join(\n",
        "        broadcast(province_df),\n",
        "        (df[\"address_postalcode\"] >= province_df[\"start_pc\"]) &\n",
        "        (df[\"address_postalcode\"] <= province_df[\"end_pc\"]),\n",
        "        how=\"left\"\n",
        "    ).drop(\"start_pc\", \"end_pc\")\n",
        "\n",
        "    log_dataframe_summary(df_with_province.limit(100), label=\"Sample with Provinces\", logger=logger)\n",
        "    return df_with_province\n"
      ],
      "metadata": {
        "id": "oBwSxJcfEpHB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def expand_handover_services(df: DataFrame, logger: Logger = LOGGER) -> DataFrame:\n",
        "    \"\"\"\n",
        "    Expands handoverServices into binary flags.\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.withColumn(\n",
        "        \"handoverServices_array\",\n",
        "        from_json(\"handoverServices\", ArrayType(StringType()))\n",
        "    )\n",
        "\n",
        "    distinct_services = (\n",
        "        df.select(explode(\"handoverServices_array\").alias(\"service\"))\n",
        "        .distinct()\n",
        "        .rdd.flatMap(lambda x: x)\n",
        "        .collect()\n",
        "    )\n",
        "\n",
        "    for service in distinct_services:\n",
        "        df = df.withColumn(\n",
        "            f\"handover_{service}\",\n",
        "            array_contains(col(\"handoverServices_array\"), service).cast(\"int\")\n",
        "        )\n",
        "\n",
        "    df = df.drop(\"handoverServices_array\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "xRwUDapzEvab"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def view_logs(path: str = LOG_FILE):\n",
        "    \"\"\"\n",
        "    Reads and returns the contents of NDJSON log file.\n",
        "    \"\"\"\n",
        "    return spark.read.json(path)\n"
      ],
      "metadata": {
        "id": "qsM_M-o5E2zo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Runs the full pipeline: loads, flattens, unions, enriches, masks, logs and returns output with address masking.\n",
        "    \"\"\"\n",
        "    logger = LOGGER  # Ensure logger is initialized\n",
        "\n",
        "    # Load and flatten each brand, and assign globals & dictionary\n",
        "    for brand in BRAND_PATHS:\n",
        "        try:\n",
        "            get_data_by_brand(brand, logger=logger)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    if not BRAND_DATAFRAMES:\n",
        "        logger.error(json.dumps({\n",
        "            \"event\": \"no_dataframes_loaded\",\n",
        "            \"message\": \"All brand files failed to load or flatten.\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }))\n",
        "        raise RuntimeError(\"No dataframes were successfully loaded.\")\n",
        "\n",
        "    # Log summaries of flat dataframes\n",
        "    for brand, df in BRAND_DATAFRAMES.items():\n",
        "        log_dataframe_summary(df, label=f\"{brand} DataFrame\", logger=logger)\n",
        "\n",
        "    # Align all DataFrames to widest schema and union\n",
        "    df_all_brands = union_all_brands(BRAND_DATAFRAMES, logger=logger)\n",
        "    log_dataframe_summary(df_all_brands, label=\"Combined Brands DataFrame\", logger=logger)\n",
        "\n",
        "    # Union with province from postal code\n",
        "    df_with_province = enrich_with_province(df_all_brands, province_df, logger=logger)\n",
        "\n",
        "    # One-hot encode Handover_services\n",
        "    df_final = expand_handover_services(df_with_province, logger=logger)\n",
        "\n",
        "    # Embedd GDPR masking\n",
        "    df_final = check_access_and_mask(df_final, logger=logger)\n",
        "\n",
        "    # View logs\n",
        "    logs_df = view_logs(path=LOG_FILE)\n",
        "\n",
        "    # Step 7: Return logs & Dataframe\n",
        "    return df_final, logs_df\n"
      ],
      "metadata": {
        "id": "AatjNE1GE9-R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigger Main and display output\n",
        "'''\n",
        "You will need to input .env here to pass authentification\n",
        "'''\n",
        "df_final, logs_df = main()\n",
        "df_final.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL7GRjVYKmhl",
        "outputId": "1c312b29-aca2-4ee0-e7d8-d84e96127bc6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Raw schema for brand 'clp':\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- cityName: string (nullable = true)\n",
            " |    |-- countryCode: string (nullable = true)\n",
            " |    |-- countryName: string (nullable = true)\n",
            " |    |-- houseNumber: string (nullable = true)\n",
            " |    |-- postalcode: string (nullable = true)\n",
            " |    |-- streetName: string (nullable = true)\n",
            " |-- branchId: string (nullable = true)\n",
            " |-- commercialName: string (nullable = true)\n",
            " |-- ensign: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |-- geoCoordinates: struct (nullable = true)\n",
            " |    |-- latitude: double (nullable = true)\n",
            " |    |-- longitude: double (nullable = true)\n",
            " |-- handoverServices: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- isActive: boolean (nullable = true)\n",
            " |-- moreInfoUrl: string (nullable = true)\n",
            " |-- placeId: long (nullable = true)\n",
            " |-- placeSearchOpeningHours: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- closes: long (nullable = true)\n",
            " |    |    |-- date: string (nullable = true)\n",
            " |    |    |-- isOpenForTheDay: boolean (nullable = true)\n",
            " |    |    |-- isToday: boolean (nullable = true)\n",
            " |    |    |-- opens: long (nullable = true)\n",
            " |-- placeType: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- longName: string (nullable = true)\n",
            " |    |-- placeTypeDescription: string (nullable = true)\n",
            " |-- routeUrl: string (nullable = true)\n",
            " |-- sellingPartners: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- sourceStatus: string (nullable = true)\n",
            " |-- temporaryClosures: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- from: string (nullable = true)\n",
            " |    |    |-- till: string (nullable = true)\n",
            "\n",
            "\n",
            "🔍 Raw schema for brand 'okay':\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- cityName: string (nullable = true)\n",
            " |    |-- countryCode: string (nullable = true)\n",
            " |    |-- countryName: string (nullable = true)\n",
            " |    |-- houseNumber: string (nullable = true)\n",
            " |    |-- postalcode: string (nullable = true)\n",
            " |    |-- streetName: string (nullable = true)\n",
            " |-- branchId: string (nullable = true)\n",
            " |-- commercialName: string (nullable = true)\n",
            " |-- ensign: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |-- geoCoordinates: struct (nullable = true)\n",
            " |    |-- latitude: double (nullable = true)\n",
            " |    |-- longitude: double (nullable = true)\n",
            " |-- handoverServices: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- isActive: boolean (nullable = true)\n",
            " |-- moreInfoUrl: string (nullable = true)\n",
            " |-- placeId: long (nullable = true)\n",
            " |-- placeSearchOpeningHours: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- closes: long (nullable = true)\n",
            " |    |    |-- date: string (nullable = true)\n",
            " |    |    |-- isOpenForTheDay: boolean (nullable = true)\n",
            " |    |    |-- isToday: boolean (nullable = true)\n",
            " |    |    |-- opens: long (nullable = true)\n",
            " |-- placeType: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- longName: string (nullable = true)\n",
            " |    |-- placeTypeDescription: string (nullable = true)\n",
            " |-- routeUrl: string (nullable = true)\n",
            " |-- sellingPartners: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- sourceStatus: string (nullable = true)\n",
            " |-- temporaryClosures: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- from: string (nullable = true)\n",
            " |    |    |-- till: string (nullable = true)\n",
            "\n",
            "\n",
            "🔍 Raw schema for brand 'spar':\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- cityName: string (nullable = true)\n",
            " |    |-- countryCode: string (nullable = true)\n",
            " |    |-- countryName: string (nullable = true)\n",
            " |    |-- houseNumber: string (nullable = true)\n",
            " |    |-- postalcode: string (nullable = true)\n",
            " |    |-- streetName: string (nullable = true)\n",
            " |-- branchId: string (nullable = true)\n",
            " |-- commercialName: string (nullable = true)\n",
            " |-- ensign: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |-- geoCoordinates: struct (nullable = true)\n",
            " |    |-- latitude: double (nullable = true)\n",
            " |    |-- longitude: double (nullable = true)\n",
            " |-- isActive: boolean (nullable = true)\n",
            " |-- moreInfoUrl: string (nullable = true)\n",
            " |-- placeId: long (nullable = true)\n",
            " |-- placeSearchOpeningHours: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- closes: long (nullable = true)\n",
            " |    |    |-- date: string (nullable = true)\n",
            " |    |    |-- isOpenForTheDay: boolean (nullable = true)\n",
            " |    |    |-- isToday: boolean (nullable = true)\n",
            " |    |    |-- opens: long (nullable = true)\n",
            " |-- placeType: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- longName: string (nullable = true)\n",
            " |    |-- placeTypeDescription: string (nullable = true)\n",
            " |-- routeUrl: string (nullable = true)\n",
            " |-- sourceStatus: string (nullable = true)\n",
            " |-- temporaryClosures: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "\n",
            "🔍 Raw schema for brand 'dats':\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- cityName: string (nullable = true)\n",
            " |    |-- countryCode: string (nullable = true)\n",
            " |    |-- countryName: string (nullable = true)\n",
            " |    |-- houseNumber: string (nullable = true)\n",
            " |    |-- postalcode: string (nullable = true)\n",
            " |    |-- streetName: string (nullable = true)\n",
            " |-- branchId: string (nullable = true)\n",
            " |-- commercialName: string (nullable = true)\n",
            " |-- ensign: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |-- geoCoordinates: struct (nullable = true)\n",
            " |    |-- latitude: double (nullable = true)\n",
            " |    |-- longitude: double (nullable = true)\n",
            " |-- isActive: boolean (nullable = true)\n",
            " |-- moreInfoUrl: string (nullable = true)\n",
            " |-- placeId: long (nullable = true)\n",
            " |-- placeType: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- longName: string (nullable = true)\n",
            " |    |-- placeTypeDescription: string (nullable = true)\n",
            " |-- routeUrl: string (nullable = true)\n",
            " |-- sourceStatus: string (nullable = true)\n",
            " |-- temporaryClosures: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "\n",
            "🔍 Raw schema for brand 'cogo':\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- cityName: string (nullable = true)\n",
            " |    |-- countryCode: string (nullable = true)\n",
            " |    |-- countryName: string (nullable = true)\n",
            " |    |-- houseNumber: string (nullable = true)\n",
            " |    |-- postalcode: string (nullable = true)\n",
            " |    |-- streetName: string (nullable = true)\n",
            " |-- branchId: string (nullable = true)\n",
            " |-- commercialName: string (nullable = true)\n",
            " |-- ensign: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |-- geoCoordinates: struct (nullable = true)\n",
            " |    |-- latitude: double (nullable = true)\n",
            " |    |-- longitude: double (nullable = true)\n",
            " |-- handoverServices: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- isActive: boolean (nullable = true)\n",
            " |-- moreInfoUrl: string (nullable = true)\n",
            " |-- placeId: long (nullable = true)\n",
            " |-- placeSearchOpeningHours: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- closes: long (nullable = true)\n",
            " |    |    |-- date: string (nullable = true)\n",
            " |    |    |-- isOpenForTheDay: boolean (nullable = true)\n",
            " |    |    |-- isToday: boolean (nullable = true)\n",
            " |    |    |-- opens: long (nullable = true)\n",
            " |-- placeType: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- longName: string (nullable = true)\n",
            " |    |-- placeTypeDescription: string (nullable = true)\n",
            " |-- routeUrl: string (nullable = true)\n",
            " |-- sellingPartners: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- sourceStatus: string (nullable = true)\n",
            " |-- temporaryClosures: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "🔐 Enter access key to view full address: ··········\n",
            "+-----+----------------+-------------------+-------------------+-------------------+------------------+------------------+--------+---------------------------+---------+------------+-----------------------+------------------------+------------------+--------+---------------------------------------------------+-------+------------+------------------+------------------------------+-------------------------------------------------------------+---------------+------------+-----------------+---------------+-----------------------+-----------------------+-----------------------------+----------------------------+-----------------------------+\n",
            "|Brand|address_cityName|address_countryCode|address_countryName|address_houseNumber|address_postalcode|address_streetName|branchId|commercialName             |ensign_id|ensign_name |geoCoordinates_latitude|geoCoordinates_longitude|handoverServices  |isActive|moreInfoUrl                                        |placeId|placeType_id|placeType_longName|placeType_placeTypeDescription|routeUrl                                                     |sellingPartners|sourceStatus|temporaryClosures|province       |handover_CSOP_ORDERABLE|handover_COLLECTNEXTDAY|handover_HOMEDELNEXTDAYDRIVER|handover_HOMEDELIVERYNEXTDAY|handover_PARCELCOLLECTNEXTDAY|\n",
            "+-----+----------------+-------------------+-------------------+-------------------+------------------+------------------+--------+---------------------------+---------+------------+-----------------------+------------------------+------------------+--------+---------------------------------------------------+-------+------------+------------------+------------------------------+-------------------------------------------------------------+---------------+------------+-----------------+---------------+-----------------------+-----------------------+-----------------------------+----------------------------+-----------------------------+\n",
            "|clp  |AALST           |BE                 |België             |41                 |9300              |BRUSSELSE STEENWEG|4156    |AALST (COLRUYT)            |8        |COLR_Colruyt|50.933074              |4.0538972               |[\"CSOP_ORDERABLE\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/4156|902    |1           |Winkel            |Winkel                        |https://maps.apple.com/?daddr=50.933074,4.0538972            |[\"QUALITY\"]    |AC          |[]               |Oost-Vlaanderen|1                      |0                      |0                            |0                           |0                            |\n",
            "|clp  |AALTER          |BE                 |België             |66                 |9880              |LOSTRAAT          |4218    |AALTER (COLRUYT)           |8        |COLR_Colruyt|51.0784761             |3.4500133               |[\"CSOP_ORDERABLE\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/4218|946    |1           |Winkel            |Winkel                        |https://maps.apple.com/?daddr=51.0784761,3.4500133           |[\"QUALITY\"]    |AC          |[]               |Oost-Vlaanderen|1                      |0                      |0                            |0                           |0                            |\n",
            "|clp  |AARSCHOT        |BE                 |België             |241                |3200              |LEUVENSESTEENWEG  |4222    |AARSCHOT (COLRUYT)         |8        |COLR_Colruyt|50.9760369             |4.8110969               |[\"CSOP_ORDERABLE\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/4222|950    |1           |Winkel            |Winkel                        |https://maps.apple.com/?daddr=50.9760369,4.8110969           |[\"QUALITY\"]    |AC          |[]               |Vlaams-Brabant |1                      |0                      |0                            |0                           |0                            |\n",
            "|clp  |AARSCHOT        |BE                 |België             |65                 |3200              |GASTHUISSTRAAT    |6927    |AARSCHOT Gasthuis (COLRUYT)|8        |COLR_Colruyt|50.988161998           |4.841193764             |[\"CSOP_ORDERABLE\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/6927|4020   |1           |Winkel            |Winkel                        |https://maps.apple.com/?daddr=50.988161998000,4.8411937640000|[\"QUALITY\"]    |AC          |[]               |Vlaams-Brabant |1                      |0                      |0                            |0                           |0                            |\n",
            "|clp  |ALSEMBERG       |BE                 |België             |19                 |1652              |BRUSSELSESTEENWEG |4138    |ALSEMBERG (COLRUYT)        |8        |COLR_Colruyt|50.7415212             |4.336719                |[\"CSOP_ORDERABLE\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/4138|886    |1           |Winkel            |Winkel                        |https://maps.apple.com/?daddr=50.7415212,4.336719            |[\"QUALITY\"]    |AC          |[]               |Vlaams-Brabant |1                      |0                      |0                            |0                           |0                            |\n",
            "+-----+----------------+-------------------+-------------------+-------------------+------------------+------------------+--------+---------------------------+---------+------------+-----------------------+------------------------+------------------+--------+---------------------------------------------------+-------+------------+------------------+------------------------------+-------------------------------------------------------------+---------------+------------+-----------------+---------------+-----------------------+-----------------------+-----------------------------+----------------------------+-----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write parquet in partitions per Brand\n",
        "df_final.write.mode(\"overwrite\").partitionBy(\"Brand\").parquet(\"/content/brand_output\")\n"
      ],
      "metadata": {
        "id": "IYyoc9pCMZxl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all Parquet files from output\n",
        "df_parquet = spark.read.parquet(\"/content/brand_output\")\n",
        "\n",
        "# Show data sample\n",
        "df_parquet.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPWWHFu8uIAU",
        "outputId": "ff2657b7-f7e8-4935-b1f4-08776a7e5767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------------+-------------------+-------------------+------------------+------------------+--------+---------------------------+---------+---------------+-----------------------+------------------------+----------------------------------------------------------------+--------+------------------------------------------------------------------------------------------+-------+------------+------------------+------------------------------+-------------------------------------------------------------+---------------------------+------------+-----------------+---------------+-----------------------+-----------------------+-----------------------------+----------------------------+-----------------------------+-----+\n",
            "|address_cityName|address_countryCode|address_countryName|address_houseNumber|address_postalcode|address_streetName|branchId|commercialName             |ensign_id|ensign_name    |geoCoordinates_latitude|geoCoordinates_longitude|handoverServices                                                |isActive|moreInfoUrl                                                                               |placeId|placeType_id|placeType_longName|placeType_placeTypeDescription|routeUrl                                                     |sellingPartners            |sourceStatus|temporaryClosures|province       |handover_CSOP_ORDERABLE|handover_COLLECTNEXTDAY|handover_HOMEDELNEXTDAYDRIVER|handover_HOMEDELIVERYNEXTDAY|handover_PARCELCOLLECTNEXTDAY|Brand|\n",
            "+----------------+-------------------+-------------------+-------------------+------------------+------------------+--------+---------------------------+---------+---------------+-----------------------+------------------------+----------------------------------------------------------------+--------+------------------------------------------------------------------------------------------+-------+------------+------------------+------------------------------+-------------------------------------------------------------+---------------------------+------------+-----------------+---------------+-----------------------+-----------------------+-----------------------------+----------------------------+-----------------------------+-----+\n",
            "|AALST           |BE                 |België             |xxx                |9300              |xxx               |8529    |AALST (BIO-PLANET)         |1        |COLR_Bio-Planet|50.9422555             |3.9976593               |[\"COLLECTNEXTDAY\",\"CSOP_ORDERABLE\"]                             |true    |https://www.bioplanet.be/wps/portal/bioplanet/nl/home/winkels/detail/aalst-bio-planet-8529|3577   |6           |Afhaalpunt        |Afhaalpunt                    |https://maps.apple.com/?daddr=50.9422555,3.9976593           |[\"QUALITY\",\"BIOBE\"]        |AC          |[]               |Oost-Vlaanderen|1                      |1                      |0                            |0                           |0                            |cogo |\n",
            "|AALST           |BE                 |België             |xxx                |9300              |xxx               |7717    |AALST (COLRUYT)            |8        |COLR_Colruyt   |50.9329969             |4.0543827               |[\"HOMEDELNEXTDAYDRIVER\",\"COLLECTNEXTDAY\",\"PARCELCOLLECTNEXTDAY\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/7717                                       |2861   |6           |Afhaalpunt        |Afhaalpunt                    |https://maps.apple.com/?daddr=50.9329969,4.0543827           |[\"CLPBE\",\"BOIRBE\",\"FDBGBE\"]|AC          |[]               |Oost-Vlaanderen|0                      |1                      |1                            |0                           |1                            |cogo |\n",
            "|AALTER          |BE                 |België             |xxx                |9880              |xxx               |7814    |AALTER (COLRUYT)           |8        |COLR_Colruyt   |51.0780228639          |3.449460268             |[\"PARCELCOLLECTNEXTDAY\",\"COLLECTNEXTDAY\",\"HOMEDELNEXTDAYDRIVER\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/7814                                       |2956   |6           |Afhaalpunt        |Afhaalpunt                    |https://maps.apple.com/?daddr=51.0780228639,3.449460268      |[\"CLPBE\",\"BOIRBE\",\"FDBGBE\"]|AC          |[]               |Oost-Vlaanderen|0                      |1                      |1                            |0                           |1                            |cogo |\n",
            "|AARSCHOT        |BE                 |België             |xxx                |3200              |xxx               |7809    |AARSCHOT (COLRUYT)         |8        |COLR_Colruyt   |50.9763446             |4.8114575               |[\"PARCELCOLLECTNEXTDAY\",\"HOMEDELNEXTDAYDRIVER\",\"COLLECTNEXTDAY\"]|true    |https://www.colruyt.be/nl/colruyt-openingsuren/7809                                       |2951   |6           |Afhaalpunt        |Afhaalpunt                    |https://maps.apple.com/?daddr=50.9763446,4.8114575           |[\"CLPBE\",\"BOIRBE\",\"FDBGBE\"]|AC          |[]               |Vlaams-Brabant |0                      |1                      |1                            |0                           |1                            |cogo |\n",
            "|AARSCHOT        |BE                 |België             |xxx                |3200              |xxx               |6980    |Aarschot Gasthuis (COLRUYT)|8        |COLR_Colruyt   |50.987763              |4.841172                |[\"COLLECTNEXTDAY\",\"PARCELCOLLECTNEXTDAY\"]                       |true    |https://www.colruyt.be/nl/colruyt-openingsuren/6980                                       |4044   |6           |Afhaalpunt        |Afhaalpunt                    |https://maps.apple.com/?daddr=50.987763000000,4.8411720000000|[\"CLPBE\",\"BOIRBE\"]         |AC          |[]               |Vlaams-Brabant |0                      |1                      |0                            |0                           |1                            |cogo |\n",
            "+----------------+-------------------+-------------------+-------------------+------------------+------------------+--------+---------------------------+---------+---------------+-----------------------+------------------------+----------------------------------------------------------------+--------+------------------------------------------------------------------------------------------+-------+------------+------------------+------------------------------+-------------------------------------------------------------+---------------------------+------------+-----------------+---------------+-----------------------+-----------------------+-----------------------------+----------------------------+-----------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check individual brand dataframes\n",
        "df_dats.show(5, truncate=False)"
      ],
      "metadata": {
        "id": "0vmaZ6QyB5kk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c429ba1b-4017-45de-cb44-28b929af14e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------------+-------------------+-------------------+------------------+---------------------+--------+---------------------------+---------+-----------+-----------------------+------------------------+--------+------------------------------------------------------------------------+-------+------------+------------------+------------------------------+------------------------------------------------+------------+-----------------+\n",
            "|address_cityName|address_countryCode|address_countryName|address_houseNumber|address_postalcode|address_streetName   |branchId|commercialName             |ensign_id|ensign_name|geoCoordinates_latitude|geoCoordinates_longitude|isActive|moreInfoUrl                                                             |placeId|placeType_id|placeType_longName|placeType_placeTypeDescription|routeUrl                                        |sourceStatus|temporaryClosures|\n",
            "+----------------+-------------------+-------------------+-------------------+------------------+---------------------+--------+---------------------------+---------+-----------+-----------------------+------------------------+--------+------------------------------------------------------------------------+-------+------------+------------------+------------------------------+------------------------------------------------+------------+-----------------+\n",
            "|AALST           |BE                 |België             |41                 |9300              |BRUSSELSE STEENWEG   |3016    |DATS 24 AALST              |12       |DATS_Dats  |50.932996              |4.054331                |true    |https://customer.dats24.be/wps/portal/datscustomer/nl/b2c/locator#!/3016|2355   |8           |Tankstation       |Tankstation                   |https://maps.apple.com/?daddr=50.932996,4.054331|AC          |[]               |\n",
            "|ALSEMBERG       |BE                 |België             |17                 |1652              |BRUSSELSESTEENWEG    |2014    |DATS 24 ALSEMBERG          |12       |DATS_Dats  |50.741285              |4.336491                |true    |https://customer.dats24.be/wps/portal/datscustomer/nl/b2c/locator#!/2014|2283   |8           |Tankstation       |Tankstation                   |https://maps.apple.com/?daddr=50.741285,4.336491|AC          |[]               |\n",
            "|AMAY            |BE                 |België             |247                |4540              |CHAUSSEE DE TONGRES  |3884    |DATS 24 AMAY               |12       |DATS_Dats  |50.557326              |5.305699                |true    |https://customer.dats24.be/wps/portal/datscustomer/nl/b2c/locator#!/3884|2423   |8           |Tankstation       |Tankstation                   |https://maps.apple.com/?daddr=50.557326,5.305699|AC          |[]               |\n",
            "|ANDERLECHT      |BE                 |België             |824                |1070              |BERGENSESTEENWEG     |3787    |DATS 24 ANDERLECHT VEEWEIDE|12       |DATS_Dats  |50.827856              |4.302371                |true    |https://customer.dats24.be/wps/portal/datscustomer/nl/b2c/locator#!/3787|2404   |8           |Tankstation       |Tankstation                   |https://maps.apple.com/?daddr=50.827856,4.302371|AC          |[]               |\n",
            "|ANDERLUES       |BE                 |België             |2                  |6150              |CHAUSSEE DE CHARLEROI|3805    |DATS 24 ANDERLUES          |12       |DATS_Dats  |50.405769              |4.273682                |true    |https://customer.dats24.be/wps/portal/datscustomer/nl/b2c/locator#!/3805|2411   |8           |Tankstation       |Tankstation                   |https://maps.apple.com/?daddr=50.405769,4.273682|AC          |[]               |\n",
            "+----------------+-------------------+-------------------+-------------------+------------------+---------------------+--------+---------------------------+---------+-----------+-----------------------+------------------------+--------+------------------------------------------------------------------------+-------+------------+------------------+------------------------------+------------------------------------------------+------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "'''\n",
        "====NB!! Only use if parquet files are corrupted====\n",
        "'''\n",
        "# Remove old corrupted Parquet output\n",
        "#shutil.rmtree(\"/content/brand_output\", ignore_errors=True)\n",
        "shutil.rmtree(\"/content/data\", ignore_errors=True)"
      ],
      "metadata": {
        "id": "crJoXQ-zvhSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a .gitignore file\n",
        "with open(\".gitignore\", \"w\") as f:\n",
        "    f.write(\".env\\n\")\n"
      ],
      "metadata": {
        "id": "8Y9GsExGE2SB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZzY7GOYE68y",
        "outputId": "a88b0881-b6a9-4756-b742-26cc623d5f3a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n",
            "[master (root-commit) c214b2d] Initial commit\n",
            " 1575 files changed, 361776 insertions(+)\n",
            " create mode 100644 .config/.last_opt_in_prompt.yaml\n",
            " create mode 100644 .config/.last_survey_prompt.yaml\n",
            " create mode 100644 .config/.last_update_check.json\n",
            " create mode 100644 .config/active_config\n",
            " create mode 100644 .config/config_sentinel\n",
            " create mode 100644 .config/configurations/config_default\n",
            " create mode 100644 .config/default_configs.db\n",
            " create mode 100644 .config/gce\n",
            " create mode 100644 .config/hidden_gcloud_config_universe_descriptor_data_cache_configs.db\n",
            " create mode 100644 .config/logs/2025.06.09/13.36.04.848227.log\n",
            " create mode 100644 .config/logs/2025.06.09/13.36.27.909045.log\n",
            " create mode 100644 .config/logs/2025.06.09/13.36.37.104044.log\n",
            " create mode 100644 .config/logs/2025.06.09/13.36.39.150228.log\n",
            " create mode 100644 .config/logs/2025.06.09/13.36.48.334074.log\n",
            " create mode 100644 .config/logs/2025.06.09/13.36.49.093999.log\n",
            " create mode 100644 .gitignore\n",
            " create mode 100644 assignment.log\n",
            " create mode 100644 brand_output/._SUCCESS.crc\n",
            " create mode 100644 brand_output/Brand=clp/.part-00000-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet.crc\n",
            " create mode 100644 brand_output/Brand=clp/part-00000-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet\n",
            " create mode 100644 brand_output/Brand=cogo/.part-00004-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet.crc\n",
            " create mode 100644 brand_output/Brand=cogo/part-00004-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet\n",
            " create mode 100644 brand_output/Brand=dats/.part-00003-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet.crc\n",
            " create mode 100644 brand_output/Brand=dats/part-00003-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet\n",
            " create mode 100644 brand_output/Brand=okay/.part-00001-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet.crc\n",
            " create mode 100644 brand_output/Brand=okay/part-00001-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet\n",
            " create mode 100644 brand_output/Brand=spar/.part-00002-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet.crc\n",
            " create mode 100644 brand_output/Brand=spar/part-00002-ea715fbf-2ce9-4dd2-8c9b-c754d4133f65.c000.snappy.parquet\n",
            " create mode 100644 brand_output/_SUCCESS\n",
            " create mode 100644 data/clp-places.json\n",
            " create mode 100644 data/cogo-colpnts.json\n",
            " create mode 100644 data/dats-places.json\n",
            " create mode 100644 data/okay-places.json\n",
            " create mode 100644 data/spar-places.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3.tgz\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/LICENSE\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/NOTICE\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/R/lib/sparkr.zip\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/README.md\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/RELEASE\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/beeline\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/beeline.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/docker-image-tool.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/find-spark-home\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/find-spark-home.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/load-spark-env.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/load-spark-env.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/pyspark\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/pyspark.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/pyspark2.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/run-example\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/run-example.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/spark-class\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-class.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/spark-class2.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/spark-connect-shell\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/spark-shell\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-shell.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-shell2.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/spark-sql\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-sql.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-sql2.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/spark-submit\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-submit.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/spark-submit2.cmd\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/bin/sparkR\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/sparkR.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/bin/sparkR2.cmd\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/conf/log4j2.properties.template\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/conf/metrics.properties.template\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/conf/spark-env.sh.template\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/conf/workers.template\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/graphx/followers.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/graphx/users.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/als/test.data\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/license.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/pic_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/als.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/pi.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/sort.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/RoaringBitmap-0.9.38.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/aircompressor-0.21.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/arrow-format-11.0.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/arrow-memory-core-11.0.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/arrow-memory-netty-11.0.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/arrow-vector-11.0.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/avro-1.11.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/avro-ipc-1.11.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/avro-mapred-1.11.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/blas-3.0.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-codec-1.15.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-compress-1.22.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-io-2.11.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-annotations-2.14.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-core-2.14.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-databind-2.14.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.14.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.14.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.14.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/janino-3.1.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/javassist-3.25.0-GA.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jcl-over-slf4j-2.0.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jersey-client-2.36.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jersey-common-2.36.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jersey-container-servlet-2.36.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jersey-container-servlet-core-2.36.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jersey-hk2-2.36.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jersey-server-2.36.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/joda-time-2.12.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jpam-1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/json-1.8.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jta-1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/jul-to-slf4j-2.0.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-client-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-client-api-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-apiextensions-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-apps-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-autoscaling-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-batch-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-certificates-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-common-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-coordination-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-core-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-discovery-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-events-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-extensions-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-metrics-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-networking-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-node-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-policy-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-rbac-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-scheduling-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/kubernetes-model-storageclass-6.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/log4j-1.2-api-2.19.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/log4j-api-2.19.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/log4j-core-2.19.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/log4j-slf4j2-impl-2.19.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/metrics-core-4.2.15.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/metrics-graphite-4.2.15.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/metrics-jmx-4.2.15.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/metrics-json-4.2.15.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/metrics-jvm-4.2.15.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-all-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-buffer-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-codec-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-codec-http-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-codec-http2-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-codec-socks-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-common-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-handler-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-handler-proxy-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-resolver-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.87.Final-linux-aarch_64.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.87.Final-linux-x86_64.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.87.Final-osx-aarch_64.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.87.Final-osx-x86_64.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.87.Final.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/objenesis-3.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/okio-1.15.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/orc-core-1.8.4-shaded-protobuf.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/orc-mapreduce-1.8.4-shaded-protobuf.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/orc-shims-1.8.4.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/parquet-column-1.12.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/parquet-common-1.12.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/parquet-encoding-1.12.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/parquet-format-structures-1.12.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/parquet-hadoop-1.12.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/parquet-jackson-1.12.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/pickle-1.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/protobuf-java-2.5.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/rocksdbjni-7.9.2.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/scala-compiler-2.12.17.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/scala-library-2.12.17.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/scala-parser-combinators_2.12-2.1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/scala-reflect-2.12.17.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/shims-0.9.38.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/slf4j-api-2.0.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/snakeyaml-1.33.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/snappy-java-1.1.10.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-catalyst_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-core_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-graphx_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-hive_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-kvstore_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-launcher_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-mesos_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-mllib_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-network-common_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-repl_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-sketch_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-sql_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-streaming_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-tags_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-unsafe_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spark-yarn_2.12-3.4.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/tink-1.7.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/xbean-asm9-shaded-4.22.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/xz-1.9.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/jars/zstd-jni-1.5.2-5.jar\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/.coveragerc\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/.gitignore\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/MANIFEST.in\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/README.md\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/Makefile\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/make.bat\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/make2.bat\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/_static/copybutton.js\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/development/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/lib/pyspark.zip\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/mypy.ini\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/_globals.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/accumulators.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/broadcast.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/context.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/daemon.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/errors/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/files.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/install.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/join.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/common.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/image.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_tuning.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_slow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_groupby_slow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_slow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/profiler.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/py.typed\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/rdd.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resource/information.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/serializers.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/shell.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/shuffle.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/column.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/client.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/context.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/group.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/session.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_client.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/types.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/sql/window.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/statcounter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/status.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/util.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/version.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/pyspark/worker.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/run-tests\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/run-tests-with-coverage\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/run-tests.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/setup.cfg\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/setup.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/people.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/people1.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/python/test_support/userlibrary.py\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/decommission-slave.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/decommission-worker.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/slaves.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/spark-config.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/spark-daemon.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/spark-daemons.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-all.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-connect-server.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-history-server.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-master.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-slave.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-slaves.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-worker.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/start-workers.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-all.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-connect-server.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-history-server.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-master.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-slave.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-slaves.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-worker.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/stop-workers.sh\n",
            " create mode 100755 spark-3.4.1-bin-hadoop3/sbin/workers.sh\n",
            " create mode 100644 spark-3.4.1-bin-hadoop3/yarn/spark-3.4.1-yarn-shuffle.jar\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ]
}